# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FqLMwPDr-55UK5D95JGIE3SQ376EMDSP
"""

!pip install pyspark

!pip install faker

!pip install item

!pip install install-jdk

!pip install findspark



from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType,DateType,FloatType
from faker import Faker
from pyspark.sql.functions import sum,desc
import random
from datetime import datetime,timedelta
import item
from google.colab import files #

# Создание объекта SparkSession
spark = SparkSession.builder \
    .appName("StudentDataGeneration") \
    .getOrCreate()

#список 7 товаров
data4 = [
    {"tovar_id": 1,"name":"Мука"},
    {"tovar_id": 2,"name":"Рис"},
    {"tovar_id": 3,"name":"Хлеб"},
    {"tovar_id": 4,"name": "Мясо" },
    {"tovar_id": 5,"name": "Пельмени" },
    {"tovar_id": 6,"name": "Сливочное масло" },
    {"tovar_id": 7,"name": "Молоко" },
]

#columns4 = ["tovar_id","name"]

names = [ item["name"] for item in data4 ]

# Определение схемы покупок для DataFrame
schema5 = StructType([
    StructField("ID", IntegerType(), nullable=False),
    StructField("DataProduct", DateType(), nullable=False),
    StructField("UserId", IntegerType(), nullable=False),
    StructField("Product", StringType(), nullable=False),
    StructField("Quantity", IntegerType(), nullable=False),
    StructField("Price", IntegerType(), nullable=False),

    ])

# Инициализация Faker для генерации данных
fake = Faker('Ru_RU')

# Задаем начальную и конечную даты
start_date = datetime(2024, 1, 1)
end_date = datetime(2024, 7, 29)

# Расчет количества дней между датами
delta = end_date - start_date
random_days = random.randint(0, delta.days)

# Генерация случайной даты
random_date = start_date + timedelta(days=random_days)

print(f"Случайная дата: {random_date.strftime('%Y-%m-%d')}")

#Генерация случайных данных
user_input = int(input("Введите число - границу массива"))
print(user_input)
data5 = []
for i in range(1, user_input):
    id = i
    userid = random.randint(1, 7)
    j = random.randint(1, 6)
    product = names[j]

    # Расчет количества дней между датами
    delta = end_date - start_date
    random_days = random.randint(0, delta.days)

    # Генерация случайной даты
    random_date = start_date + timedelta(days=random_days)
    dataproduct = random_date

    quantity = random.randint(1, 12)
    price = random.randint(100, 2000)

    data5.append((id, dataproduct,userid, product, quantity, price))

# Создание DataFrame
df5 = spark.createDataFrame(data5, schema5)

# Первые 5 строк DataFrame
df5.show(5)

# Путь для сохранения файла
output_path = "1T_data4.csv"

# Выгрузка в csv
df5.coalesce(1).write.csv(output_path, header=True)

# Остановить SparkSession
spark.stop()